以下に、**予約システムの“落とし穴”と実践的な対策**、そして **テナントごとに 5分／15分のスロット粒度を混在させる方法** を、Fastify＋PostgreSQL 前提でまとめます。前回のAPI仕様・DDLにそのまま乗ります（`tenant_settings.granularity_min` を活用）。

---

## 1) 予約システムで気を付けること（実務で事故りやすい順）

1. **ダブルブッキング（同時更新）**

   * 対策：在庫確保は**条件付きUPDATE**（`available_capacity > 0`）＋**行ロック**で原子的に。複数スロットは**昇順でFOR UPDATE**してからまとめて減算。
   * テスト：同一スロットへ100並列POST → 成功1/失敗99を必ず再現。

2. **Idempotency不備（重複POST）**

   * 対策：`Idempotency-Key` 必須、本文ハッシュも保存して\*\*“同一入力→同一応答”\*\*、差異は `409 conflict`。

3. **可用性返却と確定の“整合性ギャップ”**

   * 対策：空き照会はあくまで参考・確定は予約時の減算。UIは**直後の再検証**／**予約確定時の再計算**を前提に。

4. **粒度（5分/15分）と施術時間の不整合**

   * 対策：**“粒度の倍数”規約**（後述）。`duration_min`・`buffer_*_min` はテナントの `granularity_min` の倍数でしか登録できないよう**バリデーション/トリガ**で強制。

5. **バッファ不足／清掃時間の取り忘れ**

   * 対策：サービスに `buffer_before_min / buffer_after_min` を持たせ、可用性判定・確保の両方で**必ず連続枠に含める**。

6. **営業時間・休業・担当者休暇の反映漏れ**

   * 対策：`business_hours` / `holidays` / `resource_time_offs` を元に**スロット再生成ジョブ**（夜間＋イベント駆動）。変更検知→該当日のみ再生成。

7. **キャンセル期限とノーショー課金の法的リスク**

   * 対策：**同意バージョン・時刻・IP**を `consents` に保存。`cancel_cutoff_min` 超過は `cancel_forbidden`。ノーショーは `grace_min` 経過後に `off_session` 決済。

8. **Webhookの冪等化**

   * 対策：`webhook_events(provider,event_id)` をユニーク。失敗はDLQで再試行。

9. **タイムゾーン／夏時間**

   * 対策：DBはUTC、APIはテナントTZ（例：Asia/Tokyo）。**丸め（quantize）をUTCで**行い、UI変換のみTZ。

10. **大規模テナントでのスロット総数膨張**

* 対策：**粒度はテナント単位**（15分の店には15分枠のみ生成）。さらに**期間上限**（例：60～90日）と**インデックス**最適化。

11. **レート制限・Bot攻撃**

* 対策：`/public/*` はIPレート制限、reCAPTCHA等の二段構え。`X-Request-Id` で追跡。

12. **監査・トレーサビリティ**

* 対策：`audit_logs` に before/after を保存（PIIはマスク）。決済/在庫/予約変更は必ず記録。

13. **SLO未達（ピーク時）**

* 対策：空き照会は**短TTLキャッシュ＋ETag**、結果は**フラット配列**で最小化。読みはReplica、書きはPrimary。

14. **設定変更の移行手順欠如**（営業時間や粒度変更）

* 対策：**メンテナンスフラグ**→該当日のスロットを再生成→完了後にフラグ解除。途中予約はマイグレーションルールで保護。

15. **データ品質（電話/メール重複・名寄せ）**

* 対策：`customers` にテナント＋メール/電話の**ユニーク制約**、正規化・重複マージ機構。

---

## 2) 5分／15分スロットをテナントごとに混在させる方法

### 推奨：**テナント単位の粒度可変**（いまのDDL/設計でOK）

`tenant_settings.granularity_min` を使い、**各テナントで 5 or 15** を選択。
\*\*不変条件（Invariants）\*\*を守れば実装はシンプルです。

**Invariant A（量子化）**

* すべてのスロット `start_at/end_at` は `granularity_min` の**整数倍境界**に揃える。

**Invariant B（倍数制約）**

* `services.duration_min`, `buffer_before_min`, `buffer_after_min` は `granularity_min` の**倍数**のみ許可。

  * 実装：アプリ側バリデーション＋（望ましければ）DBトリガで強制（下に例）。

**Invariant C（連続枠の確保）**

* 予約時に必要な連続コマ数 `k = ceil( (duration + buffers) / granularity_min )` を算出し、
  **`k` 連続スロットすべてで `available_capacity>0`** を確認 → まとめてデクリメント。

  * ※複合資源時は**全リソース×k スロット**で成立したときのみコミット。

**スロット生成（テナント粒度 g = granularity\_min）**

1. 営業日×リソースごとに、営業時間を g で量子化（休暇等で間引き）。
2. `timeslots(tenant_id, resource_id, start_at, end_at=start_at+g, available_capacity=resource.capacity)` をUpsert。
3. 廃止/時間変更は差分適用（監査を残す）。

**空き照会**

* `service_id` から `duration+buffers` と**提供可能リソース**（`service_resources`）を取得。
* 期間内の `timeslots.available_capacity>0` を**時間昇順**で取得→アプリ側で**連続k判定**（軽量）。
* 返却は**フラット配列**（開始時刻候補のみ or timeslot\_id 群）。

**予約確定（単一リソース例）**（擬似コード）

```ts
// k 連続 timeslot を昇順で取得してロック
const rows = await tx.query(`
  SELECT id FROM timeslots
   WHERE tenant_id=$1 AND resource_id=$2
     AND start_at >= $3 AND end_at <= $4
   ORDER BY start_at
   FOR UPDATE
`, [tenant, resource, start, start + k*g]);

if (rows.length !== k) throw SoldOut;

const ok = await tx.query(`
  UPDATE timeslots
     SET available_capacity = available_capacity - 1
   WHERE id = ANY($1) AND available_capacity > 0
   RETURNING id
`, [rows.map(r=>r.id)]);

if (ok.rowCount !== k) throw SoldOut; // どれかが0だった

// bookings / booking_items 挿入 → コミット
```

**メリット**

* 15分テナントに**無駄な5分スロット**を作らず済む（テーブル膨張を抑制）。
* API/DBは**テナント境界**で完結し、他テナントの粒度差は影響しない。
* 既存DDLの `tenant_settings.granularity_min` をそのまま活用できる。

**注意点**

* サービス登録時に**倍数チェック**を強制（下のトリガ例）。
* 粒度を**途中で変更**する際は該当期間の**スロット再生成**が必要（手順は後述）。

---

### 代替案A：**全体5分ベース**（統一グリッド）

* すべてのテナントで5分スロットを生成し、15分希望の店はUIで“15分刻みに丸めて表示”。
* **利点**：実装一様。横断集計が楽。
* **欠点**：スロット数が約3倍（15分店でも5分×288コマ/日）。大規模テナントで肥大。
* **最適化**：読み取りはRedisに\*\*日次ビットセット（288bit/資源）\*\*としてキャッシュ、書き込みはDBを真実とする。

### 代替案B：**スロットレス（時間範囲排他）**

* `tstzrange`＋GiSTの**排他制約**で“同一資源の時間被りを禁止”（席や部屋のcapacity>1は別途レジャー計算が必要）。
* **利点**：スロット生成不要、変則的な長さに強い。
* **欠点**：capacity>1 と“連続k”の表現が難しく、在庫検索が重くなりがち。運用チューニング必須。
* ※初期はスロット方式を推奨。

---

## 3) 倍数制約のDBトリガ（任意：強制したい場合）

```sql
CREATE OR REPLACE FUNCTION enforce_service_granularity()
RETURNS trigger LANGUAGE plpgsql AS $$
DECLARE g INT;
BEGIN
  SELECT granularity_min INTO g FROM tenant_settings WHERE tenant_id = NEW.tenant_id;
  IF g IS NULL THEN
    RAISE EXCEPTION 'tenant % has no granularity_min', NEW.tenant_id;
  END IF;
  IF (NEW.duration_min % g <> 0)
     OR (NEW.buffer_before_min % g <> 0)
     OR (NEW.buffer_after_min % g <> 0) THEN
    RAISE EXCEPTION 'duration/buffers must be multiples of % minutes', g
      USING ERRCODE = '23514';
  END IF;
  RETURN NEW;
END; $$;

DROP TRIGGER IF EXISTS trg_services_granularity ON services;
CREATE TRIGGER trg_services_granularity
BEFORE INSERT OR UPDATE ON services
FOR EACH ROW EXECUTE FUNCTION enforce_service_granularity();
```

---

## 4) 粒度変更の手順（15分→5分 など）

1. **メンテナンスフラグON**（該当日の公開空き照会を“読み取り専用”に）
2. `tenant_settings.granularity_min` を更新。
3. 影響範囲（例：今後60日）の**スロット再生成**（`POST /v1/timeslots/generate`）

   * 既存予約は**保持**。必要なら“新グリッドに合致するよう”該当枠を占有済みに再マッピング。
4. キャッシュ/ETagバージョンをローテーション。
5. **メンテナンスフラグOFF**。
   ※ 既存予約が新粒度境界に合わない場合は「最も近い下限境界に寄せ」＋**バッファで吸収**、またはその日のみ旧粒度併用にする（設定フラグで例外運用）。

---

## 5) 可用性検索（連続k判定）のコツ

* **DB側で重い連結JOIN**をせず、`available_capacity>0` のスロットを時間順に取得し、**アプリ側で連続判定**するのが現実的に速いです。
* どうしてもSQLでやるなら、`start_at` を g 分で割った整数インデックスで**連番化**し、
  `idx - row_number()` を同一グループとみなす**ラン検出**で `count >= k` の塊を拾うやり方が定石です。

---

## 6) 追加の実装チェックリスト

* [ ] `POST /public/bookings`：**Idempotency-Key** 必須、本文ハッシュ一致でのみ再利用
* [ ] 在庫確保：**昇順ロック → 一括デクリメント**（行数一致しなければ即ロールバック）
* [ ] `services`：**粒度倍数**の検証（UI/サーバ/DB）
* [ ] 空き照会：**ETag + 短TTL**、過大範囲（>90日）は 400
* [ ] キャンセル期限：`cancel_cutoff_min` 超過は `cancel_forbidden`
* [ ] ノーショー：`grace_min` 経過 → `off_session` 課金（Webhook冪等）
* [ ] 監査：`bookings/payments` の before/after を `audit_logs` に記録
* [ ] アラート：在庫枯渇率の急上昇、ロック待ち時間、Webhook失敗率
* [ ] マイグレーション：粒度変更時の再生成ジョブ＆ロールバック手順

---

### まとめ

* **最適解**は、**テナント単位で粒度（5/15）を持たせ**、サービス時間・バッファを**その倍数に限定**、予約時は**連続kコマ**を**原子的に確保**する方式です。
* これで“行数爆発”と“ダブルブッキング”の双方を現実的に抑えられます。
* さらに伸ばしたくなったら、読み取りは**ビットセットキャッシュ**、内部処理は**Outbox＋ジョブ**でスケールさせてください。

必要であれば、**連続k判定のTypeScript実装雛形**や、**スロット再生成ジョブ**のコード（Fastify＋BullMQ/Cloud Tasks）も即用意します。
